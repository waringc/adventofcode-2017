{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Advent of Code 2017\n",
    "\n",
    "My Solutions to 2017 Advent of Code (http://adventofcode.com) in Python.\n",
    "\n",
    "They may not be all perfect but they work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Load Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import operator\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Function for Loading Puzzle Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(day):\n",
    "    filename = \"input/\"+ day + \"-input.txt\"\n",
    "\n",
    "    try:\n",
    "        return open(filename)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Failed to load file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 1: Inverse Captcha\n",
    "\n",
    "####Part1:\n",
    "\n",
    "To solve I create a rotated version of the input string.  We can than iterate and add any numbers which are in the same position in the original and rotated list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1089"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def captcha(text,rotate):\n",
    "    text_r = text[rotate:] + text[:rotate]\n",
    "    total = 0\n",
    "    \n",
    "    for i in range(0,len(text)):\n",
    "        if text_r[i] == text[i]:\n",
    "            total += int(text[i])\n",
    "            \n",
    "    return total\n",
    "\n",
    "#test\n",
    "assert captcha(\"1122\",1) == 3\n",
    "assert captcha(\"1111\",1) == 4\n",
    "assert captcha(\"1234\",1) == 0\n",
    "assert captcha(\"91212129\",1) ==9\n",
    "captcha(load_data(\"day1\").read(),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2\n",
    "\n",
    "Instead of rotating by one, rotate by half the length of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1156"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "assert captcha(\"1212\",2) == 6\n",
    "assert captcha(\"1221\",2) == 0\n",
    "assert captcha(\"123425\",3) == 4\n",
    "assert captcha(\"123123\",3) ==12\n",
    "assert captcha(\"12131415\",4) ==4\n",
    "\n",
    "r = int(len(load_data(\"day1\").read())/2)\n",
    "captcha(load_data(\"day1\").read(),r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 2: Corruption Checksum\n",
    "\n",
    "###Part 1:\n",
    "\n",
    "The solution for this is mostly about correctly formatting the data. I split the input into a list of lists.  The lower level lists are each row and the higher level list is the entire spreadsheet.  We than count the difference of each rows max and min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45972"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def checksum(spreadsheet):\n",
    "    total = 0\n",
    "    \n",
    "    for row in spreadsheet:\n",
    "        total += (max(row) - min(row))\n",
    "        \n",
    "    return total\n",
    "\n",
    "def load_ss():\n",
    "    input = []\n",
    "    for line in load_data(\"day2\"):\n",
    "        t = line.rstrip().split(\"\\t\")\n",
    "        t = list(map(int, t))\n",
    "        input.append(t)\n",
    "    return input\n",
    "\n",
    "assert checksum([[5,1,9,5],[7,5,3],[2,4,6,8]]) == 18\n",
    "\n",
    "checksum(load_ss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2:\n",
    "\n",
    "Use the same data structure as for part one.  However this time we need to iterate through each row to find which two elements in each row are divisible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_divisor(row):\n",
    "    \n",
    "    for i in range(0,len(row)-1):\n",
    "        for j in range(i+1,len(row)):\n",
    "            if row[i]%row[j] == 0.0:\n",
    "                return int(row[i]/row[j])\n",
    "            elif row[j]%row[i] == 0.0:\n",
    "                return int(row[j]/row[i])\n",
    "    return 0\n",
    "    \n",
    "\n",
    "def checksum_2(spreadsheet):\n",
    "    total = 0\n",
    "    \n",
    "    for row in spreadsheet:\n",
    "        total += get_divisor(row)\n",
    "        \n",
    "    return total\n",
    "    \n",
    "assert checksum_2([[5,9,2,8],[9,4,7,3],[3,8,6,5]]) == 9\n",
    "\n",
    "checksum_2(load_ss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 3: Spiral Memory\n",
    "\n",
    "###Part 1:\n",
    "\n",
    "The bottom right hand corner of each square is the square of odd numbers (ie 9, 25, 49, 81) we can use this to determine which square the specified number is located in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puzzle_input_day2 = 361527\n",
    "\n",
    "def spiral_dist(num):\n",
    "    square = 1\n",
    "    x = 0\n",
    "    y = 0\n",
    "    \n",
    "    #if its already the centre\n",
    "    if num == 1:\n",
    "        return 0\n",
    "    \n",
    "    #determine which square the number is in\n",
    "    #ie square is the size of square sides that the square containing the number will have\n",
    "    while True:\n",
    "        square += 2\n",
    "        if num <= square ** 2:\n",
    "            break\n",
    "            \n",
    "    #this is teh value in bottom right corner of the square\n",
    "    #it is the biggest number in the square containing the number of interest\n",
    "    corner = square ** 2\n",
    "    \n",
    "    #calculate number of squares or layers before current square\n",
    "    #no matter what we must travel this distance\n",
    "    dist = math.floor(square/2)\n",
    "    \n",
    "    #calculate distance from nearest mid point in square side\n",
    "    #we will need to travel this distance in addtion to the number of squares before current square\n",
    "    dist += min([abs(num - (corner - dist)), abs(num - (corner - 3 * dist)),\n",
    "                 abs(num - (corner - 5 * dist)),abs(num - (corner - 7 * dist))])\n",
    "    \n",
    "    return dist\n",
    "\n",
    "\n",
    "assert spiral_dist(1) == 0\n",
    "assert spiral_dist(12) == 3\n",
    "assert spiral_dist(23) == 2\n",
    "assert spiral_dist(1024) == 31\n",
    "\n",
    "spiral_dist(puzzle_input_day2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2:\n",
    "\n",
    "\n",
    "Try brute forcing using numpy.  Create the spiral in a numpy array and not when we encounter a first number above the puzzle input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer is: 363010\n"
     ]
    }
   ],
   "source": [
    "#generate square\n",
    "size = 32\n",
    "global day2_match\n",
    "day2_match = False\n",
    "\n",
    "def sum_neighbours(x,y):\n",
    "    global day2_match\n",
    "    square[x,y] = square[x-1,y] + square[x+1,y] + square[x,y-1] + square[x,y + 1] + square[x-1,y - 1] + square[x-1,y +1] + square[x + 1,y-1] + square[x + 1,y + 1]\n",
    "    \n",
    "    if (square[x,y] > puzzle_input_day2) and day2_match == False:\n",
    "        print(\"Answer is: \" + str(int(square[x,y])))\n",
    "        day2_match = True\n",
    "    return\n",
    "\n",
    "def add_square(num):\n",
    "    x =  size//2 + num\n",
    "    y =  size//2 + num\n",
    "    \n",
    "    #right side\n",
    "    for i in range(0,(num*2)):\n",
    "        x -= 1\n",
    "        sum_neighbours(x,y)\n",
    "        \n",
    "    #top\n",
    "    for j in range(0,(num*2)):\n",
    "        y -= 1\n",
    "        sum_neighbours(x,y)\n",
    "    \n",
    "    #left\n",
    "    for k in range(0,(num*2)):\n",
    "        x += 1\n",
    "        sum_neighbours(x,y)\n",
    "\n",
    "    #bottom\n",
    "    for m in range(0,(num*2)):\n",
    "        y += 1\n",
    "        sum_neighbours(x,y)\n",
    "    \n",
    "    return\n",
    "    \n",
    "   \n",
    "#initalize array and set center to 1\n",
    "square = np.zeros((size,size))\n",
    "square[size//2,size//2] = 1\n",
    "\n",
    "#add squares\n",
    "for i in range (1,5):\n",
    "    add_square(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 4: High-Entropy Passphrases\n",
    "\n",
    "###Part 1:\n",
    "\n",
    "Approach is to create a set of each line and add each word one by one.  If word already in set break and don't count that passcode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def valid_passcode(passcode):\n",
    "    pc_set = set()\n",
    "    for word in passcode:\n",
    "        if word in pc_set:\n",
    "            return 0\n",
    "        else:\n",
    "            pc_set.add(word)\n",
    "    return 1\n",
    "\n",
    "pc_count = 0\n",
    "\n",
    "for line in load_data(\"day4\"):\n",
    "    pc = line.rstrip().split(\" \")\n",
    "    pc_count += valid_passcode(pc)\n",
    "\n",
    "assert valid_passcode(\"aa bb cc dd ee\".split(\" \")) == 1\n",
    "assert valid_passcode(\"aa bb cc dd aa\".split(\" \")) == 0\n",
    "assert valid_passcode(\"aa bb cc dd aaa\".split(\" \")) == 1\n",
    "\n",
    "pc_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2:\n",
    "\n",
    "Solve using a dict to compare pairs of strings and see if they are anagrams.  Repeat for every possible pairing of words in each passcode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_anagram(word1,word2):\n",
    "    #add each letter in word 1 to dict\n",
    "    #subtract each letter in word 2\n",
    "    #if the dict values sum to 0 it must be an anagram\n",
    "    letter_dict1 = {}\n",
    "    letter_dict2 = {}\n",
    "    \n",
    "    for letter in word1:\n",
    "        letter_dict1[letter] = letter_dict1.get(letter, 0) + 1\n",
    "        \n",
    "    for letter in word2:\n",
    "        letter_dict2[letter] = letter_dict2.get(letter, 0) + 1\n",
    "        \n",
    "    if letter_dict1 == letter_dict2:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "#use is_anagram to compare all pairs in string for anagrams\n",
    "def valid_passcode_anagram(passcode):\n",
    "    for i in range(0,len(passcode)-1):\n",
    "        for j in range(i+1,len(passcode)):\n",
    "            if is_anagram(passcode[i],passcode[j]):\n",
    "                return 0\n",
    "    return 1\n",
    "\n",
    "#valid_passcode_anagram(\"abcde xyz ecdab\".split(\" \"))\n",
    "\n",
    "assert valid_passcode_anagram(\"abcde fghij\".split(\" \")) == 1\n",
    "assert valid_passcode_anagram(\"abcde xyz ecdab\".split(\" \")) == 0\n",
    "assert valid_passcode_anagram(\"a ab abc abd abf abj\".split(\" \")) == 1\n",
    "assert valid_passcode_anagram(\"iiii oiii ooii oooi oooo\".split(\" \")) == 1\n",
    "assert valid_passcode_anagram(\"oiii ioii iioi iiio\".split(\" \")) == 0\n",
    "\n",
    "pc_count_anagram = 0\n",
    "for line in load_data(\"day4\"):\n",
    "    pc = line.rstrip().split(\" \")\n",
    "    pc_count_anagram += valid_passcode_anagram(pc)\n",
    "\n",
    "pc_count_anagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 5: A Maze of Twisty Trampolines, All Alike\n",
    "\n",
    "###Part 1:\n",
    "\n",
    "Create array with instructions and update as required until we jump \"outside\" of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356945"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load instructions into a list of integers\n",
    "instructions = load_data(\"day5\").read()\n",
    "instructions = instructions.rstrip().split(\"\\n\")\n",
    "instructions = list(map(int,instructions))\n",
    "\n",
    "#count jumps\n",
    "def count_jumps(instructions):\n",
    "    ptr = 0\n",
    "    counter = 0\n",
    "    length = len(instructions)\n",
    "    while True:\n",
    "        instruct = instructions[ptr]\n",
    "        instructions[ptr] += 1\n",
    "        ptr += instruct\n",
    "        counter += 1\n",
    "        if ptr > length - 1:\n",
    "            return counter\n",
    "        \n",
    "assert count_jumps([0,3,0,1,-3]) == 5\n",
    "\n",
    "count_jumps(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2:\n",
    "\n",
    "Same as previous solution but update the offsets.  It runs a little slower!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28372145"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reload instructions into a list of integers\n",
    "instructions = load_data(\"day5\").read()\n",
    "instructions = instructions.rstrip().split(\"\\n\")\n",
    "instructions = list(map(int,instructions))\n",
    "\n",
    "\n",
    "#count jumps\n",
    "def count_jumps_p2(instructions):\n",
    "    ptr = 0\n",
    "    counter = 0\n",
    "    length = len(instructions)\n",
    "    while True:\n",
    "        instruct = instructions[ptr]\n",
    "        \n",
    "        if instructions[ptr] >= 3:\n",
    "            instructions[ptr] -= 1\n",
    "        else:\n",
    "            instructions[ptr] += 1\n",
    "            \n",
    "        ptr += instruct\n",
    "        counter += 1\n",
    "        if ptr > length - 1:\n",
    "            return counter\n",
    "        \n",
    "assert count_jumps_p2([0,3,0,1,-3]) == 10\n",
    "\n",
    "count_jumps_p2(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 6: Memory Reallocation\n",
    "\n",
    "###Part 1:\n",
    "\n",
    "Loop through the array incrementing the registers as required.  Use a set to track the previous sets we have encountered.  Return the answer once a match to the set is found.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is:  12841\n"
     ]
    }
   ],
   "source": [
    "#load inital registers\n",
    "reg = load_data(\"day6\").read()\n",
    "reg = reg.rstrip().split(\"\\t\")\n",
    "reg = list(map(int,reg))\n",
    "\n",
    "def mem_reallocate(reg):\n",
    "\n",
    "    #set of registers we have seen\n",
    "    past_reg = set()\n",
    "    past_reg.add(\"-\".join(str(x) for x in reg))\n",
    "    \n",
    "    #step count \n",
    "    counter = 0\n",
    "\n",
    "    while True:\n",
    "        max_i = reg.index(max(reg))\n",
    "        max_v = reg[max_i]\n",
    "        reg[max_i] = 0\n",
    "        \n",
    "        for i in range(1, max_v+1):\n",
    "            reg[(max_i+i)%16] += 1\n",
    "            \n",
    "        counter += 1\n",
    "        \n",
    "        new_reg_str = \"-\".join(str(x) for x in reg)\n",
    "        \n",
    "        if new_reg_str in past_reg:\n",
    "            return counter, reg\n",
    "        \n",
    "        past_reg.add(new_reg_str)\n",
    "    \n",
    "ans, new_reg = mem_reallocate(reg)\n",
    "\n",
    "print(\"The answer is: \",str(ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2:\n",
    "Use the answer from part 1.  Run until we get a match to this register."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8038"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def mem_reallocate_p2(reg):\n",
    "\n",
    "    #set of registers we have seen\n",
    "    past_reg = \"-\".join(str(x) for x in reg)\n",
    "    \n",
    "    #step count \n",
    "    counter = 0\n",
    "\n",
    "    while True:\n",
    "        max_i = reg.index(max(reg))\n",
    "        max_v = reg[max_i]\n",
    "        reg[max_i] = 0\n",
    "        \n",
    "        for i in range(1, max_v+1):\n",
    "            reg[(max_i+i)%16] += 1\n",
    "            \n",
    "        counter += 1\n",
    "        \n",
    "        new_reg_str = \"-\".join(str(x) for x in reg)\n",
    "        \n",
    "        if new_reg_str == past_reg:\n",
    "            return counter\n",
    "\n",
    "mem_reallocate_p2(new_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 7: Recursive Circus\n",
    "\n",
    "###Part 1:\n",
    "\n",
    "We need to load data into two dicts one with the node weights and one with children of the nodes.  We can then use recurision to determine the depth of tree below each node.  The node with the greatest depth below it will be the root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth: 6\nRoot: veboyvy\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "weights = {}\n",
    "children = {}\n",
    "\n",
    "#load data into two dicts, one for weights and 1 for children\n",
    "for line in load_data(\"day7\"):\n",
    "    \n",
    "        # add weight to weights dict\n",
    "        node = line.rstrip().split(\" \")[0]\n",
    "        weight = line.rstrip().split(\" \")[1]\n",
    "        weight = weight[weight.find(\"(\")+1:weight.find(\")\")]\n",
    "        weights[node] = weight\n",
    "        \n",
    "        #add children to children dict\n",
    "        if line.count(\" \") > 1:\n",
    "            children_raw = line.rstrip().split(\"-> \")[1]\n",
    "            children_raw = children_raw.strip().split(\",\")\n",
    "            children[node] = [child.strip() for child in children_raw]\n",
    "\n",
    "def depth(node,level):\n",
    "    if node not in children.keys():\n",
    "        return level + 1\n",
    "    for child in children[node]:\n",
    "        return depth(child,level+1)\n",
    "\n",
    "max_depth = 0\n",
    "root = \"\"\n",
    "\n",
    "#find node with greatest depth below it\n",
    "for node in weights.keys():\n",
    "    node_d = depth(node,0)\n",
    "    if node_d > max_depth:\n",
    "        max_depth = node_d\n",
    "        root = node\n",
    "        \n",
    "print(\"Max depth: \" + str(max_depth))\n",
    "print(\"Root: \" + root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2:\n",
    "Calculate the subtree weights of all children of the root node.  One node will be unbalanced.  Than recursively call again on the unbalanced node.  Repeat until nodes are balanced.  This node that has all balanced children but was in a unbalanced branch must be imbalanced one.  We can than subtract the needed correction from it's known weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbalanced node: obxrn\nNew weight is: 749\n"
     ]
    }
   ],
   "source": [
    "def subtree_weight(node):\n",
    "    if node not in children.keys():\n",
    "        return int(weights[node])\n",
    "    return int(weights[node]) + sum([subtree_weight(child) for child in children[node]])\n",
    "\n",
    "def find_unbalanced_node(node):\n",
    "    weights = []\n",
    "    \n",
    "    for child in children[node]:\n",
    "        weights.append(subtree_weight(child))\n",
    "    \n",
    "\n",
    "    if len(set(weights)) == 1:\n",
    "        return node\n",
    "    \n",
    "    else:\n",
    "        index_offbalance = weights.index([x for x in weights if weights.count(x)==1][0])\n",
    "        return find_unbalanced_node(children[node][index_offbalance])\n",
    "\n",
    "    \n",
    "unbalanced = find_unbalanced_node('veboyvy')\n",
    "correct_weight = int(weights[unbalanced]) - 7\n",
    "print(\"Unbalanced node: \" + str(unbalanced))\n",
    "print(\"New weight is: \" + str(correct_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 8: I Heard You Like Registers\n",
    "\n",
    "###Part 1/Part 2:\n",
    "\n",
    "Create a queue of commands and pop them off one by one.  Use a dict to store the values of the registers.  Can modify registers in place using process_commands function.\n",
    "\n",
    "Modified process_commands to track the largest register ever encountered for part 2 of the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest final register: 7787\nLargest ever register: 8997\n"
     ]
    }
   ],
   "source": [
    "registers = {}\n",
    "commands = []\n",
    "max_register_ever = -9999\n",
    "\n",
    "commands_test = [\"b inc 5 if a > 1\",\n",
    "\"a inc 1 if b < 5\",\n",
    "\"c dec -10 if a >= 1\",\n",
    "\"c inc -20 if c == 10\"]\n",
    "\n",
    "#load data\n",
    "for line in load_data(\"day8\"):\n",
    "    commands.append(line.rstrip())\n",
    "\n",
    "#prepare register    \n",
    "def init_register(register):\n",
    "        if register not in registers.keys():\n",
    "            registers[register] = 0\n",
    "\n",
    "#check if command operation is true            \n",
    "def condition_is_true(register,operator,value):\n",
    "    if operator == \"!=\":\n",
    "        return registers[register] != int(value)\n",
    "    \n",
    "    elif operator == \"==\":\n",
    "        return registers[register] == int(value)\n",
    "    \n",
    "    elif operator == \"<=\":\n",
    "        return registers[register] <= int(value)\n",
    "    \n",
    "    elif operator == \">=\":\n",
    "        return registers[register] >= int(value)\n",
    "    \n",
    "    elif operator == \"<\":\n",
    "        return registers[register] < int(value)\n",
    "    \n",
    "    elif operator == \">\":\n",
    "        return registers[register] > int(value)\n",
    " \n",
    "#perform the command operation on register   \n",
    "def perform_operation(operand_register,operation,increment):\n",
    "    if operation ==\"inc\":\n",
    "        registers[operand_register] += int(increment)\n",
    "        \n",
    "    elif operation ==\"dec\":\n",
    "        registers[operand_register] -= int(increment)\n",
    "\n",
    "#run through queue of commands and perform them\n",
    "#return largest ever register for part 2\n",
    "def process_commands(commands):\n",
    "    max_register_ever = -9999\n",
    "    \n",
    "    while commands:\n",
    "        operand_register,operation,increment,condition,cond_register,cond_opt,cond_amount = commands.pop(0).rstrip().split(\" \")\n",
    "        \n",
    "        init_register(cond_register)\n",
    "        init_register(operand_register)\n",
    "        \n",
    "        if condition_is_true(cond_register,cond_opt,cond_amount):\n",
    "            perform_operation(operand_register,operation,increment)\n",
    "        \n",
    "        if max(registers.values()) > max_register_ever:\n",
    "            max_register_ever = max(registers.values())\n",
    "            \n",
    "    return max_register_ever\n",
    "            \n",
    "max_reg = process_commands(commands)\n",
    "print(\"Largest final register: \" + str(max(registers.values())))\n",
    "print(\"Largest ever register: \" + str(max_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 9: Stream Processing\n",
    "\n",
    "###Part 1/Part 2:\n",
    "\n",
    "Build a stack and add to it everytime we encounter a \"{\" and pop from the stack everytime we encounter \"}\".  If we see a \"<\" go into garbage mode and ignore brackets.  If we see a \"!\" ignore the next letter by removing it from the garbage stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9251, 4322]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_garbage(stream):\n",
    "    stack = []\n",
    "    count = 0\n",
    "    garbage = False\n",
    "    str = list(stream)\n",
    "    garbage_count = 0\n",
    "    while str:\n",
    "        c = str.pop(0)\n",
    "        \n",
    "        if c == \"!\":\n",
    "            str.pop(0)\n",
    "            \n",
    "        elif c != \"!\" and c != \">\" and garbage:\n",
    "            garbage_count += 1\n",
    "            \n",
    "        if not garbage:\n",
    "            if c == \"{\":\n",
    "                stack.append(\"}\")\n",
    "            elif len(stack) and c == stack[-1]:\n",
    "                stack.pop()\n",
    "                count += len(stack) + 1\n",
    "            elif c == \"<\":\n",
    "                garbage = True\n",
    "                       \n",
    "        elif c == \">\":\n",
    "            garbage = False\n",
    "            \n",
    "    return [count,garbage_count]\n",
    "\n",
    "assert process_garbage(\"{}\")[0] == 1\n",
    "assert process_garbage(\"{{{}}}\")[0] == 6\n",
    "assert process_garbage(\"{{},{}}\")[0] == 5\n",
    "assert process_garbage(\"{{{},{},{{}}}}\")[0] == 16\n",
    "assert process_garbage(\"{<a>,<a>,<a>,<a>}\")[0] == 1\n",
    "assert process_garbage(\"{{<ab>},{<ab>},{<ab>},{<ab>}}\")[0] == 9\n",
    "assert process_garbage(\"{{<!!>},{<!!>},{<!!>},{<!!>}}\")[0] == 9\n",
    "assert process_garbage(\"{{<a!>},{<a!>},{<a!>},{<ab>}}\")[0] == 3\n",
    "\n",
    "#load data\n",
    "stream = load_data(\"day9\").read().rstrip()\n",
    "process_garbage(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 10: Knot Hash\n",
    "\n",
    "###Part 1:\n",
    "\n",
    "Use a list and modify the number ordering per the instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23715"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def knot_hash(elements,lengths):\n",
    "    #intialize\n",
    "    l = [x for x in range(0,elements)]\n",
    "    skip_size = 0\n",
    "    ptr = 0\n",
    "    \n",
    "    for length in lengths:\n",
    "        \n",
    "        rev_l = []\n",
    "        #get elements\n",
    "        for i in range(0,length):\n",
    "            rev_l.append(l[(ptr+i)%elements])\n",
    "            \n",
    "        #reverse\n",
    "        rev_l = rev_l[::-1]\n",
    "        \n",
    "        #replace in list\n",
    "        for i in range(0,length):\n",
    "            l[(ptr+i)%elements] =rev_l[i]\n",
    "        \n",
    "        ptr += length + skip_size\n",
    "        skip_size += 1\n",
    "\n",
    "    return l[0] * l[1]\n",
    "        \n",
    "    \n",
    "    \n",
    "assert knot_hash(5,[3,4,1,5]) == 12\n",
    "\n",
    "lengths = load_data('day10').read().rstrip().split(\",\")\n",
    "lengths = list(map(int,lengths))\n",
    "\n",
    "knot_hash(256,lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2:\n",
    "\n",
    "Gets a little trickier here.  Modify the function from part 1 to generate the sparse hash of the input. Dense hash than converts the sparse hash into a fixed length hexidecimal dense hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'541dc3180fd4b72881e39cf925a50253'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert input to ascii codes\n",
    "lengths = load_data('day10').read().rstrip()\n",
    "\n",
    "def sparse_hash(elements,lengths):\n",
    "    #intialize\n",
    "    lengths = [ord(c) for c in lengths]\n",
    "    lengths = lengths + [17, 31, 73, 47, 23]\n",
    "\n",
    "    l = [x for x in range(0,elements)]\n",
    "    skip_size = 0\n",
    "    ptr = 0\n",
    "    \n",
    "    for j in range(0,64):\n",
    "        for length in lengths:\n",
    "            \n",
    "            rev_l = []\n",
    "            #get elements\n",
    "            for i in range(0,length):\n",
    "                rev_l.append(l[(ptr+i)%elements])\n",
    "                \n",
    "            #reverse\n",
    "            rev_l = rev_l[::-1]\n",
    "            \n",
    "            #replace in list\n",
    "            for i in range(0,length):\n",
    "                l[(ptr+i)%elements] =rev_l[i]\n",
    "            \n",
    "            ptr += length + skip_size\n",
    "            skip_size += 1\n",
    "\n",
    "    return l\n",
    "\n",
    "def dense_hash(sparse_hash):\n",
    "    dense=[]\n",
    "    hex_string = []\n",
    "    for i in range(0,16):\n",
    "        t = sparse_hash[(16*i):(16*i + 16)]\n",
    "        dt = t[0]\n",
    "        for x in t[1:16]:\n",
    "            dt = dt ^ x\n",
    "        dense.append(dt)\n",
    "        \n",
    "    #convert to hex\n",
    "    for c in dense:\n",
    "        hex_c = '{:x}'.format(c)\n",
    "        #correct due to problem with hex not putting 0 in front of single digit nums\n",
    "        if len(hex_c) == 1:\n",
    "            hex_c = \"0\" + hex_c\n",
    "        hex_string.append(hex_c)\n",
    "        \n",
    "    return \"\".join(hex_string)\n",
    "\n",
    "\n",
    "assert dense_hash(sparse_hash(256,\"\"))  == \"a2582a3a0e66e6e86e3812dcb672a272\"\n",
    "assert dense_hash(sparse_hash(256,\"AoC 2017\"))  == \"33efeb34ea91902bb2f59c9920caa6cd\"\n",
    "assert dense_hash(sparse_hash(256,\"1,2,3\")) == \"3efbe78a8d82f29979031a4aa0b16a9d\" \n",
    "assert dense_hash(sparse_hash(256,\"1,2,4\"))  == \"63960835bcdc130f0b66d7ff4f6a5a8e\" \n",
    "\n",
    "dense_hash(sparse_hash(256,lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 11: Hex Ed\n",
    "\n",
    "###Part 1:\n",
    "\n",
    "Solved using cube dimensions for hexes described here: https://www.redblobgames.com/grids/hexagons/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fewest_steps(steps):\n",
    "    x = 0\n",
    "    y = 0\n",
    "    z = 0\n",
    "    for step in steps:\n",
    "        \n",
    "        if step ==\"nw\":\n",
    "            y += 1\n",
    "            x += -1\n",
    "            \n",
    "        elif step == \"n\":\n",
    "            y += 1\n",
    "            z += -1\n",
    "            \n",
    "        elif step == \"ne\":\n",
    "            x += 1\n",
    "            z += -1\n",
    "        \n",
    "        elif step == \"se\":\n",
    "            x += 1\n",
    "            y += -1\n",
    "        \n",
    "        elif step == \"s\":\n",
    "            y -= 1\n",
    "            z += 1\n",
    "            \n",
    "        elif step == \"sw\":\n",
    "            x += -1\n",
    "            z += 1\n",
    "            \n",
    "    return max(abs(x),abs(y),abs(z))\n",
    "\n",
    "\n",
    "assert fewest_steps(['ne','ne','ne'])  == 3\n",
    "assert fewest_steps(['ne','ne','sw','sw'])  == 0\n",
    "assert fewest_steps(['ne','ne','s','s'])  == 2\n",
    "assert fewest_steps(['se','sw','se','sw','sw'])  == 3\n",
    "\n",
    "fewest_steps(load_data('day11').read().rstrip().split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2:\n",
    "Using the function from part 1, we just iterate through all the steps one by one and record the longest distance ever from the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567\n"
     ]
    }
   ],
   "source": [
    "steps = load_data('day11').read().rstrip().split(\",\")\n",
    "max_dist = 0\n",
    "\n",
    "for i in range(0,len(steps)):\n",
    "    max_dist = max(max_dist,fewest_steps(steps[0:i]))\n",
    "    \n",
    "print(max_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 12: Digital Plumber\n",
    "\n",
    "###Part 1:\n",
    "Build up the input graph in a dict.  Than use DFS to traverse starting at program/node 0 and count how many different nodes we visit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data and create graph\n",
    "rg = load_data('day12').read().rstrip().split(\"\\n\")\n",
    "g = {}\n",
    "\n",
    "for path in rg:\n",
    "    node = int(path.split(\" <-> \")[0])\n",
    "    connections = path.split(\" <-> \")[1].split(\",\")\n",
    "    connections = [int(x.strip(' ')) for x in connections]\n",
    "    \n",
    "    g[node] = connections\n",
    "    \n",
    "#dfs the graph to find everything connected to program \"0\"\n",
    "def find_group(g,start_program):\n",
    "    visited = set()\n",
    "    stack = [start_program]\n",
    "    while stack:\n",
    "        program = stack.pop()\n",
    "        if program not in visited:\n",
    "            visited.add(program)\n",
    "            for connection in g[program]:\n",
    "                stack.append(connection)\n",
    "                \n",
    "    return visited\n",
    "\n",
    "len(find_group(g,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2:\n",
    "Iteratively call find_group on the list of the nodes.  After each run remove nodes that were visited and then re-run on one of the remaining nodes.  Count the number of time this is repeated until no nodes remain to find the groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n"
     ]
    }
   ],
   "source": [
    "nodes = list(g.keys())\n",
    "groups = 0\n",
    "\n",
    "while nodes:\n",
    "    visited = list(find_group(g,nodes.pop(0)))\n",
    "    groups += 1\n",
    "    nodes = [x for x in nodes if x not in visited]\n",
    "    \n",
    "print(groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 13: Packet Scanners\n",
    "\n",
    "###Part 1:\n",
    "Create a dict to store firewall and its layers using load_fw().  Than cycle through the firewall for each second.  If scanner is at 0 for that scanner increase severity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1704"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load and prep firewall\n",
    "def load_fw(fw_input):\n",
    "    fw_input = fw_input.rstrip().split(\"\\n\")\n",
    "    fw = {}\n",
    "    \n",
    "    #fw structure [depth,scanner_pos, update direction\n",
    "    for step in fw_input:\n",
    "        fw[int(step.split(\": \")[0])] = int(step.split(\": \")[1])\n",
    "    \n",
    "    for i in range(0,max(fw.keys())):\n",
    "        if i not in fw.keys():\n",
    "            fw[i] = 0\n",
    "            \n",
    "    return fw\n",
    "\n",
    "def calc_severity(firewall):\n",
    "    severity = 0\n",
    "    \n",
    "    for ps in range(0,max(firewall.keys())+1):\n",
    "        layer_range = firewall[ps]\n",
    "        #if no scanner\n",
    "        if layer_range == 0:\n",
    "            continue\n",
    "        #determine if the scanner is position zero when the scanner\n",
    "        #cross through this layer\n",
    "        if (ps % ((layer_range-1)*2)) == 0:\n",
    "            severity += ps * layer_range\n",
    "            \n",
    "    return severity\n",
    "        \n",
    "        \n",
    "    \n",
    "assert calc_severity(load_fw(\"0: 3\\n1: 2\\n4: 4\\n6: 4\")) == 24\n",
    "\n",
    "calc_severity(load_fw(load_data('day13').read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2:\n",
    "\n",
    "Modify the severity calculator from part 1.  Keepy increasing delay by one picosecond until the pointer is not caught.  Still a more or less brute force solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3970918"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_delay(firewall):\n",
    "\n",
    "    #iterate through different delay amounts\n",
    "    for delay in range(0,4000000):\n",
    "        caught = False\n",
    "        \n",
    "        #cycle through with the given delay to see if pointer is caught.\n",
    "        for ps in range(0,max(firewall.keys())+1):\n",
    "            layer_range = firewall[ps]\n",
    "            \n",
    "            #if no scanner\n",
    "            if layer_range == 0:\n",
    "                continue\n",
    "            \n",
    "            #determine if the scanner is position zero when the scanner\n",
    "            #cross through this layer, added in the delay components   \n",
    "            if ((ps+delay) % ((layer_range-1)*2)) == 0:\n",
    "                caught = True\n",
    "                \n",
    "        if caught == False:\n",
    "            return delay        \n",
    "    return 0\n",
    "\n",
    "assert calc_delay(load_fw(\"0: 3\\n1: 2\\n4: 4\\n6: 4\")) == 10\n",
    "\n",
    "calc_delay(load_fw(load_data('day13').read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 14: Disk Defragmentation\n",
    "\n",
    "###Part 1:\n",
    "\n",
    "We can use the hashing functions from day 10 to generate the hash.  We can than iterate through the hash to generate the hard drive grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8230\n"
     ]
    }
   ],
   "source": [
    "input = 'hfdlxzhv'\n",
    "grid = {}\n",
    "\n",
    "#make sure hash is still working\n",
    "assert dense_hash(sparse_hash(256,\"AoC 2017\"))  == \"33efeb34ea91902bb2f59c9920caa6cd\"\n",
    "\n",
    "#generate hashes\n",
    "for i in range(0,128):\n",
    "    row = \"\"\n",
    "    hash = dense_hash(sparse_hash(256,input + \"-\" +str(i)))\n",
    "    \n",
    "    for hex in hash:\n",
    "        row = row + (bin(int(hex, 16))[2:].zfill(4))\n",
    "    grid[i] = [int(x) for x in row]\n",
    "    \n",
    "    \n",
    "#count number of positions used\n",
    "squares_used = 0\n",
    "\n",
    "for row in grid.keys():\n",
    "    squares_used += sum(grid[row])\n",
    "    \n",
    "print(squares_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2:\n",
    "We scan through the grid until we encounter an occupied square.  We than empty that square out and all connected squares to get the grouping.  We continue this until we have scanned through all squares in the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1103\n"
     ]
    }
   ],
   "source": [
    "regions = 0\n",
    "\n",
    "#grid = {}\n",
    "#grid[0] = [0,0,1,1]\n",
    "#grid[1] = [1,0,0,1]\n",
    "#grid[2] = [0,1,0,1]\n",
    "#grid[3] = [1,0,0,1]\n",
    "\n",
    "\n",
    "rows = 128\n",
    "cols = 128\n",
    "for row in range(0,rows):\n",
    "    for col in range(0,cols):\n",
    "        stack = []\n",
    "    \n",
    "        #if we encounter an occupied square\n",
    "        if grid[row][col] == 1:\n",
    "            #increment regions\n",
    "            regions += 1\n",
    "            grid[row][col] = 0\n",
    "            stack.append([row,col])\n",
    "        \n",
    "        #clear out all adjacent squares using a stack\n",
    "        while stack:\n",
    "            c_row,c_col = stack.pop()\n",
    "            #check above\n",
    "            if c_row - 1 >= 0:\n",
    "                if grid[c_row-1][c_col] == 1:\n",
    "                    grid[c_row-1][c_col] = 0\n",
    "                    stack.append([c_row-1,c_col])\n",
    "                    \n",
    "            #check below\n",
    "            if c_row + 1 <= rows - 1:\n",
    "                if grid[c_row+1][c_col] == 1:\n",
    "                    grid[c_row+1][c_col] = 0\n",
    "                    stack.append([c_row+1,c_col])\n",
    "    \n",
    "            #check right\n",
    "            if c_col + 1 <= cols - 1:\n",
    "                if grid[c_row][c_col+1] == 1:\n",
    "                    grid[c_row][c_col+1] = 0\n",
    "                    stack.append([c_row,c_col+1])\n",
    "                    \n",
    "            \n",
    "            #check left\n",
    "            if c_col - 1 >= 0:\n",
    "                if grid[c_row][c_col-1] == 1:\n",
    "                    grid[c_row][c_col-1] = 0\n",
    "                    stack.append([c_row,c_col-1])\n",
    "                \n",
    "print(regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 15: Dueling Generators\n",
    "\n",
    "###Part 1:\n",
    "Simple brute force for loop generating numbers and counting pairs.  The bitwise AND operation with 0xFFFF sped up the process alot vs doing string manipulation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594\n"
     ]
    }
   ],
   "source": [
    "#Constants for problem\n",
    "gen_a = 703\n",
    "gen_b = 516\n",
    "\n",
    "gen_a_factor = 16807\n",
    "gen_b_factor = 48271\n",
    "\n",
    "divisor  = 2147483647\n",
    "\n",
    "matches = 0\n",
    "a_queue = []\n",
    "b_queue = []\n",
    "#loop\n",
    "for i in range(0,40000000):\n",
    "    gen_a*= gen_a_factor\n",
    "    gen_a = gen_a % divisor\n",
    "    \n",
    "    gen_b *= gen_b_factor\n",
    "    gen_b = gen_b % divisor\n",
    "    \n",
    "    #Get the int equivalent to the last 16 bits of the numbers\n",
    "    gen_a_bin = gen_a & 0xFFFF\n",
    "    gen_b_bin = gen_b & 0xFFFF\n",
    "    \n",
    "    if gen_a_bin == gen_b_bin:\n",
    "        matches += 1\n",
    "        \n",
    "\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2:\n",
    "\n",
    "Try implementing with generators to compare the pairs.  There is a seperate generator for each.  We stop after 5,000,000 comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328\n"
     ]
    }
   ],
   "source": [
    "def a_gen():\n",
    "    a = 703\n",
    "    while True:\n",
    "        a  *=16807\n",
    "        a  %= 2147483647\n",
    "    \n",
    "        if a % 4 == 0:\n",
    "            yield a\n",
    "        \n",
    "def b_gen():\n",
    "    b = 516\n",
    "    while True:\n",
    "        b  *=48271\n",
    "        b  %= 2147483647\n",
    "    \n",
    "        if b % 8 == 0:\n",
    "            yield b\n",
    "        \n",
    "# perform 5 million comparisons\n",
    "match = 0\n",
    "a = a_gen()\n",
    "b = b_gen()\n",
    "\n",
    "for _ in range(0,5000000):\n",
    "    cur_a = next(a) & 0xFFFF\n",
    "    cur_b = next(b) & 0xFFFF\n",
    "    if cur_a == cur_b:\n",
    "        match +=1\n",
    "        \n",
    "print(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 16: Permutation Promenade\n",
    "\n",
    "###Part 1:\n",
    "Create an array of the programs.  Then perform \"dance\" by performing each command in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olgejankfhbmpidc\n"
     ]
    }
   ],
   "source": [
    "#generate array\n",
    "def rotate_prog(prog,n):\n",
    "    rotate = -(n%len(prog))\n",
    "    return prog[rotate:] + prog[:rotate]\n",
    "\n",
    "def swap_pos(prog,A,B):\n",
    "    temp=prog[A]\n",
    "    prog[A] = prog[B]\n",
    "    prog[B] = temp\n",
    "    return prog\n",
    "\n",
    "def swap_prog(prog,A,B):\n",
    "    index_a = prog.index(A)\n",
    "    index_b = prog.index(B)\n",
    "    temp=prog[index_a]\n",
    "    prog[index_a] = prog[index_b]\n",
    "    prog[index_b] = temp\n",
    "    return prog\n",
    "    \n",
    "prog = list(\"abcdefghijklmnop\")\n",
    "\n",
    "#load data\n",
    "commands = load_data('day16').read()\n",
    "commands = commands.rstrip().split(\",\")\n",
    "\n",
    "\n",
    " \n",
    "for command in commands:\n",
    "    if command[0] == 's':\n",
    "        prog = rotate_prog(prog,int(command[1:]))\n",
    "    elif command[0] == 'p':\n",
    "        prog = swap_prog(prog,command[1],command[3])\n",
    "    elif command[0] == 'x':\n",
    "        pos = command[1:].split(\"/\")\n",
    "        prog = swap_pos(prog,int(pos[0]),int(pos[1]))\n",
    "        \n",
    "        \n",
    "print(\"\".join(prog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2:\n",
    "\n",
    "The output list of programs will start to cycle after X number cycles.  We just need to find each value of the program list at each point in the cycle.  1 billion % the cycle length will give us which location in the cycle the \"dance\" will end upon.  By doing this we avoid having to run all 1 billion iterations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\ngfabehpdojkcimnl\n"
     ]
    }
   ],
   "source": [
    "prog = list(\"abcdefghijklmnop\")\n",
    "\n",
    "#load data\n",
    "commands = load_data('day16').read()\n",
    "commands = commands.rstrip().split(\",\")\n",
    "memo = {}\n",
    "\n",
    "#Find number of repeat cycles\n",
    "encountered_set = set()\n",
    "cycle = []\n",
    "\n",
    "\n",
    "while ''.join(prog) not in encountered_set:\n",
    "    encountered_set.add(''.join(prog))\n",
    "    cycle.append(''.join(prog))\n",
    "      \n",
    "    for command in commands:\n",
    "        if command[0] == 's':\n",
    "            prog = rotate_prog(prog,int(command[1:]))\n",
    "        elif command[0] == 'p':\n",
    "            prog = swap_prog(prog,command[1],command[3])\n",
    "        elif command[0] == 'x':\n",
    "            pos = command[1:].split(\"/\")\n",
    "            prog = swap_pos(prog,int(pos[0]),int(pos[1]))\n",
    "            \n",
    "        \n",
    "print(int(1e9%len(cycle)))\n",
    "print(cycle[int(1e9%len(cycle))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 17: Spinlock\n",
    "\n",
    "###Part 1:\n",
    "The spinlock function performs the spinlock steps as specified in the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def spinlock(step_size,steps):\n",
    "    arr = [0]\n",
    "    ptr = 0\n",
    "    for step in range(1,(steps+1)):\n",
    "        ptr = ((ptr)+step_size) % (len(arr))\n",
    "        arr = arr[:(ptr+1)] + [step] + arr[(ptr+1):]\n",
    "        ptr+=1\n",
    "    return(arr[ptr+1])\n",
    "    \n",
    "assert spinlock(3,2017) == 638\n",
    "spinlock(316,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2:\n",
    "The first position in the array will always be zero. So the value to the right of zero will be the value in position 1 in the array after 50,000,000 cycles.  So we don't need to maintain and update the full array the entire time, but just track when the ptr is at position 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13326437\n"
     ]
    }
   ],
   "source": [
    "val = 0\n",
    "ptr=0\n",
    "step_size = 316\n",
    "for step in range(1,(50000000+1)):\n",
    "    ptr = ((ptr)+step_size) % (step)\n",
    "    if ptr == 0:\n",
    "        val = step\n",
    "    ptr +=1\n",
    "        \n",
    "print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 18: Duet\n",
    "\n",
    "###Part 1:\n",
    "\n",
    "First load data than cycle through performing instructions until we hit 'rcv'.  At which point break and return the last sound played. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "input = load_data('day18')\n",
    "cmd= []\n",
    "reg = {}\n",
    "\n",
    "for line in input:\n",
    "    nc = line.rstrip().split(\" \")\n",
    "    #add in place holder for lines without a value\n",
    "    if len(nc) == 2:\n",
    "        nc.append('0')\n",
    "    cmd.append(nc)\n",
    "    reg[nc[1]] = 0\n",
    "\n",
    "#process\n",
    "cmd_ptr = 0\n",
    "sound = 0\n",
    "\n",
    "while True:\n",
    "    instruct, register, value = cmd[cmd_ptr]\n",
    "\n",
    "    #check if value is another register\n",
    "    if ord(value[0]) >= 97 or ord(value[0]) >= 122:\n",
    "        value=reg[value]\n",
    "        \n",
    "    #perform commands\n",
    "    if instruct == 'set':\n",
    "        reg[register] = int(value)\n",
    "        \n",
    "    elif instruct =='mul':\n",
    "        reg[register] *= int(value)\n",
    "        \n",
    "    elif instruct == 'add':\n",
    "        reg[register] += int(value)\n",
    "        \n",
    "    elif instruct == 'mod':\n",
    "        reg[register] = reg[register] % int(value)\n",
    "        \n",
    "    elif instruct == 'jgz' and reg[register] > 0:\n",
    "        cmd_ptr += int(value)\n",
    "        continue\n",
    "        \n",
    "    elif instruct =='snd':\n",
    "        sound = reg[register]\n",
    "        \n",
    "    elif instruct =='rcv' and reg[register] != 0:\n",
    "        print(sound)\n",
    "        break\n",
    "        \n",
    "    cmd_ptr +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2:\n",
    "\n",
    "This was a little bit tricker.  We run the two programs independantly.  Run the 1st until it is deadlocked and needs to receive from the second.  While the 1st is running we place it's sends into a queue.  We than repeat the process for program 2.  We iterate back and forth between the two programs until they are both deadlocked and cannot proceed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7493\n"
     ]
    }
   ],
   "source": [
    "reg_0 = {}\n",
    "reg_1 = {}\n",
    "cmd = []\n",
    "\n",
    "#load data\n",
    "input = load_data('day18')\n",
    "for line in input:\n",
    "    nc = line.rstrip().split(\" \")\n",
    "    #add in place holder for lines without a value\n",
    "    if len(nc) == 2:\n",
    "        nc.append('0')\n",
    "    cmd.append(nc)\n",
    "    \n",
    "    if ord(nc[1]) >= 97 or ord(nc[1]) >= 122:\n",
    "        reg_0[nc[1]] = 0\n",
    "        reg_1[nc[1]] = 0\n",
    "    \n",
    "#initialize everything\n",
    "reg_0['p'] = 0\n",
    "reg_1['p'] = 1\n",
    "ptr_0 = 0\n",
    "ptr_1 = 0\n",
    "queue_0 = []\n",
    "queue_1 = []\n",
    "\n",
    "#cycle through and run each program until you can't anymore\n",
    "def cycle(reg, ptr, queue_in, queue_out,cmd):\n",
    "    snd_count = 0\n",
    "    count = 0\n",
    "    while True:\n",
    "        instruct, register, value = cmd[ptr]\n",
    "        #print(cmd[ptr])\n",
    "        #check if value is another register\n",
    "        if ord(value[0]) >= 97 or ord(value[0]) >= 122:\n",
    "            value=reg[value]\n",
    "            \n",
    "        #perform commands\n",
    "        if instruct == 'set':\n",
    "            reg[register] = int(value)\n",
    "            \n",
    "        elif instruct =='mul':\n",
    "            reg[register] *= int(value)\n",
    "            \n",
    "        elif instruct == 'add':\n",
    "            reg[register] += int(value)\n",
    "            \n",
    "        elif instruct == 'mod':\n",
    "            reg[register] = reg[register] % int(value)\n",
    "            \n",
    "        elif instruct == 'jgz':\n",
    "            \n",
    "            #can be a register or int\n",
    "            if ord(register[0]) >= 97 or ord(register[0]) >= 122:\n",
    "                register=reg[register]\n",
    "                \n",
    "            if int(register) > 0:    \n",
    "                ptr += int(value)\n",
    "                continue\n",
    "            \n",
    "        elif instruct =='snd':\n",
    "            queue_out.append(reg[register])\n",
    "            snd_count +=1\n",
    "            \n",
    "        elif instruct =='rcv':\n",
    "            if queue_in:\n",
    "                reg[register] = queue_in.pop(0)\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "        ptr +=1\n",
    "\n",
    "    return reg, ptr, queue_in, queue_out, snd_count\n",
    "\n",
    "#keep cycling both programs until dead locked\n",
    "sends = 0\n",
    "sends_tot = 0\n",
    "\n",
    "\n",
    "while True:\n",
    "    reg_0, ptr_0, queue_0, queue_1, sends = cycle(reg_0, ptr_0, queue_0, queue_1,cmd)\n",
    "    reg_1, ptr_1, queue_1, queue_0, sends = cycle(reg_1, ptr_1, queue_1, queue_0,cmd)\n",
    "    sends_tot += sends\n",
    "    if len(queue_0) == 0 and len(queue_1) == 0:\n",
    "        break\n",
    "        \n",
    "#return count\n",
    "print(sends_tot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 19: A Series of Tubes\n",
    "\n",
    "###Part 1/Part 2:\n",
    "\n",
    "Can solve part 1 and two together.  Basically the packed always continues in the same direction until a '+' is encountered.  At which point we must scan around the '+' to find a '-' or '|' to determine which direction to change.  After a packet travel through a position the path is removed.  Whenever we encounter a letter we record it for the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPYDUXANIT\nSteps taken: 17544\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "input = load_data('day19')\n",
    "tubes = []\n",
    "x = 0\n",
    "y = 0\n",
    "#term to keep track of our momentum up,down,left,right\n",
    "momentum = [1,0] \n",
    "#term to keep track of previous char\n",
    "prev_char = \"|\"\n",
    "\n",
    "#order of letters\n",
    "letters = []\n",
    "\n",
    "for line in input:\n",
    "    tubes.append(list(line.rstrip('\\n')))\n",
    "\n",
    "tubes.append([' ' for x in range(0,len(tubes[-1]))])\n",
    "\n",
    "#find out start coordinate\n",
    "for point in range(0,len(tubes[0])):\n",
    "    if tubes[x][point] != \" \":\n",
    "        y = point\n",
    "\n",
    "\n",
    "\n",
    "count = 0\n",
    "while len(letters) < 10:\n",
    "    current_char = tubes[x][y]\n",
    "    tubes[x][y] = \" \"\n",
    "    \n",
    "    #if letter    \n",
    "    if current_char in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ':\n",
    "        letters.append(current_char)\n",
    "        \n",
    "    #if '+' we need to update momentum\n",
    "    elif current_char == '+':\n",
    "        if tubes[x+1][y] != \" \":\n",
    "            momentum = [1,0]\n",
    "            \n",
    "        elif tubes[x-1][y] != \" \":\n",
    "            momentum = [-1,0]\n",
    "            \n",
    "        elif tubes[x][y-1] != \" \":\n",
    "            momentum = [0,-1]\n",
    "            \n",
    "        elif tubes[x][y+1] != \" \":\n",
    "            momentum = [0,1]\n",
    "        \n",
    "    x_diff, y_diff = momentum\n",
    "    x += x_diff\n",
    "    y += y_diff\n",
    "    count +=1\n",
    "    \n",
    "print(''.join(letters))\n",
    "print(\"Steps taken: \" + str(count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 20: Particle Swarm\n",
    "\n",
    "###Part 1:\n",
    "Create three seperate dicts for acceleration, velocity and particle position.  For each tick we add acceleration to velocity and velocity to position.   I just ran the ticks for an arbitrary large number and than found the nearest particle to the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "input = load_data('day20')\n",
    "particles = []\n",
    "velocity = []\n",
    "acel = []\n",
    "p_count = 0\n",
    "\n",
    "#process lists for processing\n",
    "for line in input:\n",
    "    p,v,a = line.rstrip().split(\", \")\n",
    "    particles.append(list(map(int,p[3:-1].rstrip().split(\",\"))))\n",
    "    velocity.append(list(map(int,v[3:-1].rstrip().split(\",\"))))\n",
    "    acel.append(list(map(int,a[3:-1].rstrip().split(\",\"))))\n",
    "\n",
    "#lets assume long term steady state at 1000 'ticks' \n",
    "for i in range(0,500):\n",
    "    collisions = {}\n",
    "    for particle in range(0,len(particles)):\n",
    "        velocity[particle] = list(map(operator.add,velocity[particle], acel[particle]))\n",
    "        particles[particle] = list(map(operator.add,particles[particle], velocity[particle]))\n",
    "\n",
    "\n",
    "#find nearest particle\n",
    "min_particle_index = 0\n",
    "min_particle_distance = 9999999999\n",
    "\n",
    "for i in range(0,len(particles)):\n",
    "    dist = abs(particles[i][0]) + abs((particles[i][1])) + abs((particles[i][2])) \n",
    "    if dist < min_particle_distance:\n",
    "        min_particle_distance = dist\n",
    "        min_particle_index = i\n",
    "        \n",
    "print(min_particle_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2:\n",
    "Used modified code from part 1.  At each tick check for a collision between particles.  Any collised particles are labelled with 'c'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "477"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "input = load_data('day20')\n",
    "particles = []\n",
    "velocity = []\n",
    "acel = []\n",
    "p_count = 0\n",
    "\n",
    "#process lists for processing\n",
    "for line in input:\n",
    "    p,v,a = line.rstrip().split(\", \")\n",
    "    particles.append(tuple(map(int,p[3:-1].rstrip().split(\",\"))))\n",
    "    velocity.append(tuple(map(int,v[3:-1].rstrip().split(\",\"))))\n",
    "    acel.append(tuple(map(int,a[3:-1].rstrip().split(\",\"))))\n",
    "\n",
    "#lets assume long term steady state at 1000 'ticks' \n",
    "for i in range(0,1000):\n",
    "    for particle in range(0,len(particles)):\n",
    "        if particles[particle] !='c':\n",
    "            velocity[particle] = tuple(map(operator.add,velocity[particle], acel[particle]))\n",
    "            particles[particle] = tuple(map(operator.add,particles[particle], velocity[particle]))\n",
    "    \n",
    "    #check for collisions\n",
    "    \n",
    "    #get list of collisions\n",
    "    collisions = set()\n",
    "    locations = Counter(particles)\n",
    "    for location in locations:\n",
    "        if locations[location] > 1:\n",
    "            collisions.add(location)       \n",
    "        \n",
    "    #update collided values\n",
    "    for particle in range(0,len(particles)):\n",
    "        if particles[particle] in collisions:\n",
    "            particles[particle] = 'c'\n",
    "            velocity[particle] = 'c'\n",
    "            acel[particle] = 'c'\n",
    "\n",
    "#count particles left\n",
    "remaining = 0\n",
    "for particle in particles:\n",
    "    if particle != 'c':\n",
    "        remaining+=1\n",
    "        \n",
    "remaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 21: Fractal Art\n",
    "\n",
    "###Part 1/Part 2:\n",
    "\n",
    "This one was pretty long.  I created a dict of the conversions for the enhancements to be able to quickly look them up.  For each enchancment input I pre-generated all the transforms(flip/rotate) and put them into this dict for lookup.  We then look at the grid and apply the enhancements to build up a new grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1879071"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load enhancement book and put into dict\n",
    "input = load_data('day21')\n",
    "\n",
    "#dict for enhancements\n",
    "eb = {}\n",
    "\n",
    "#generates all rotations and flips of an array\n",
    "def transforms(pattern):\n",
    "    res = []\n",
    "    for i in range(0,4):\n",
    "        tp = np.rot90(pattern, k = i)\n",
    "        res.append(tp)\n",
    "        res.append((np.fliplr(tp)))\n",
    "        res.append((np.flipud(tp)))\n",
    "        \n",
    "    return res\n",
    "        \n",
    "#generate the full enhancement book\n",
    "for line in input:\n",
    "    start,out = line.rstrip().split(\" => \")\n",
    "    \n",
    "    start = start.replace(\"/\", \"\")\n",
    "    out = out.replace(\"/\", \"\")\n",
    "\n",
    "    if len(start) == 4:\n",
    "        size =2\n",
    "    else:\n",
    "        size = 3\n",
    "    \n",
    "    start = np.array([1 if x == \"#\" else 0 for x in start]).reshape((size,size))\n",
    "    out = np.array([1 if x == \"#\" else 0 for x in out]).reshape((size+1,size+1))\n",
    "\n",
    "    for transform in transforms(start):\n",
    "        eb[transform.tostring()] = out\n",
    "\n",
    "#make sure book is working       \n",
    "assert (eb[np.array([0,1,0,0,0,1,1,1,1]).reshape((3,3)).tobytes()]==np.array([1,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1]).reshape(4,4)).all()\n",
    "\n",
    "#time to run!\n",
    "grid= np.array(np.array([0,1,0,0,0,1,1,1,1]).reshape(3,3))\n",
    "size = 3\n",
    "\n",
    "for k in range(0,18):\n",
    "    #if current grid divisible by two\n",
    "    if size % 2 ==0:\n",
    "        newsize = size // 2 * 3\n",
    "        new_grid = np.empty((newsize,newsize),dtype=int)\n",
    "        #row count\n",
    "        for i in range(0,size,2):\n",
    "            #col count\n",
    "            for j in range(0,size,2):\n",
    "                new_grid[i//2*3:i//2*3+3,j//2*3:j//2*3+3] = eb[grid[i//2*2:i//2*2+2,j//2*2:j//2*2+2].tobytes()]\n",
    "    #if current grid divisible by three        \n",
    "    else:\n",
    "        newsize = size // 3 * 4\n",
    "        new_grid = np.empty((newsize,newsize),dtype=int)\n",
    "        #row count\n",
    "        for i in range(0,size,3):\n",
    "            #col count\n",
    "            for j in range(0,size,2):\n",
    "                new_grid[i//3*4:i//3*4+4,j//3*4:j//3*4+4] = eb[grid[i//3*3:i//3*3+3,j//3*3:j//3*3+3].tobytes()]\n",
    "                \n",
    "    grid = new_grid\n",
    "    size = newsize\n",
    "    \n",
    "np.sum(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 22: Sporifica Virus\n",
    "\n",
    "###Part 1:\n",
    "\n",
    "To track the direction the various is tracking I used a numpy array: [[1,0],[0,-1]].  By rotating this array it will tell us which way the virus will currently need to move.  The array can be easily rotated is np.rot90.  We also need to resize the grid whenever we get to its edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5462"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load grid and put into numpy grid\n",
    "grid = []\n",
    "input = load_data('day22')\n",
    "\n",
    "for row in input:\n",
    "    grid.append([1 if x ==\"#\" else 0 for x in list(row.rstrip())])\n",
    "\n",
    "#convert to numpy    \n",
    "grid = np.array(grid)\n",
    "\n",
    "#initalize virus locations\n",
    "v_x = grid.shape[0]//2\n",
    "v_y = grid.shape[1]//2\n",
    "\n",
    "#direction matrix for virus \n",
    "v_directions = np.array([[0,-1],[1,0]])\n",
    "\n",
    "#start facing up\n",
    "v_cur = 2\n",
    "infect_count = 0\n",
    "for iteration in range(0,10000):\n",
    "    #if current grid infected\n",
    "    if grid[v_x,v_y] == 1:\n",
    "        #turn right\n",
    "        v_directions = np.rot90(v_directions, k = -1)\n",
    "        #clean\n",
    "        grid[v_x,v_y] = 0\n",
    "        \n",
    "    #if uninfected:\n",
    "    else:\n",
    "        #turn left\n",
    "        v_directions = np.rot90(v_directions, k = 1)\n",
    "        #infect\n",
    "        grid[v_x,v_y] = 1\n",
    "        infect_count+=1\n",
    "        \n",
    "    v_x += v_directions[0,1]\n",
    "    v_y += v_directions[0,0]\n",
    "    \n",
    "    #make grid larger if necessary\n",
    "    if (v_x < 0 or v_x >= grid.shape[0]) or (v_y < 0 or v_y >= grid.shape[1]):\n",
    "        #pad grid\n",
    "        grid = np.vstack((np.zeros((1,grid.shape[1]),dtype=int),grid,np.zeros((1,grid.shape[1]),dtype=int)))\n",
    "        grid = np.hstack((np.zeros((grid.shape[0],1),dtype=int),grid,np.zeros((grid.shape[0],1),dtype=int)))\n",
    "        v_x+=1\n",
    "        v_y+=1\n",
    "        \n",
    "infect_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2:\n",
    "\n",
    "Modified code from part 1 to include the new weakened and flagged states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2512135"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load grid and put into numpy grid\n",
    "#0 = clean\n",
    "#1 = infected\n",
    "#2 = weak\n",
    "#3=flagged\n",
    "grid = []\n",
    "input = load_data('day22')\n",
    "\n",
    "for row in input:\n",
    "    grid.append([1 if x ==\"#\" else 0 for x in list(row.rstrip())])\n",
    "\n",
    "#convert to numpy    \n",
    "grid = np.array(grid)\n",
    "\n",
    "#initalize virus locations\n",
    "v_x = grid.shape[0]//2\n",
    "v_y = grid.shape[1]//2\n",
    "\n",
    "#direction matrix for virus \n",
    "v_directions = np.array([[0,-1],[1,0]])\n",
    "\n",
    "#start facing up\n",
    "v_cur = 2\n",
    "infect_count = 0\n",
    "for iteration in range(0,10000000):\n",
    "    #if current grid infected\n",
    "    if grid[v_x,v_y] == 1:\n",
    "        #turn right\n",
    "        v_directions = np.rot90(v_directions, k = -1)\n",
    "        #clean\n",
    "        grid[v_x,v_y] = 3\n",
    "        \n",
    "    #if uninfected:\n",
    "    elif grid[v_x,v_y] == 0:\n",
    "        #turn left\n",
    "        v_directions = np.rot90(v_directions, k = 1)\n",
    "        #weaken\n",
    "        grid[v_x,v_y] = 2\n",
    "        \n",
    "        #if weak:\n",
    "    elif grid[v_x,v_y] == 2:\n",
    "        #no turn\n",
    "        #infect\n",
    "        grid[v_x,v_y] = 1\n",
    "        infect_count +=1\n",
    "        \n",
    "    else:\n",
    "        #rotate 180\n",
    "        v_directions = np.rot90(v_directions, k = 2)\n",
    "        #clean\n",
    "        grid[v_x,v_y] = 0\n",
    "\n",
    "        \n",
    "    v_x += v_directions[0,1]\n",
    "    v_y += v_directions[0,0]\n",
    "    \n",
    "    #make grid larger if necessary\n",
    "    if (v_x < 0 or v_x >= grid.shape[0]) or (v_y < 0 or v_y >= grid.shape[1]):\n",
    "        #pad grid\n",
    "        grid = np.vstack((np.zeros((1,grid.shape[1]),dtype=int),grid,np.zeros((1,grid.shape[1]),dtype=int)))\n",
    "        grid = np.hstack((np.zeros((grid.shape[0],1),dtype=int),grid,np.zeros((grid.shape[0],1),dtype=int)))\n",
    "        v_x+=1\n",
    "        v_y+=1\n",
    "        \n",
    "infect_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 23: Coprocessor Conflagration\n",
    "\n",
    "###Part 1:\n",
    "\n",
    "I reused/updated some of the code from day 18.  It's similar in following commands to update register values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6241\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "input = load_data('day23')\n",
    "cmd= []\n",
    "reg = {'a':0,\n",
    "       'b':0,\n",
    "       'c':0,\n",
    "       'd':0,\n",
    "       'e':0,\n",
    "       'f':0,\n",
    "       'g':0,\n",
    "       'h':0}\n",
    "\n",
    "for line in input:\n",
    "    nc = line.rstrip().split(\" \")\n",
    "    cmd.append(nc)\n",
    "\n",
    "#process\n",
    "cmd_ptr = 0\n",
    "mul_count = 0\n",
    "\n",
    "while True:\n",
    "    if cmd_ptr >= len(cmd):\n",
    "        break\n",
    "        \n",
    "    instruct, register, value = cmd[cmd_ptr]\n",
    "    #check if value is another register\n",
    "    if ord(value[0]) >= 97 and ord(value[0]) <= 122:\n",
    "        value=reg[value]\n",
    "    \n",
    "    #check if reg value is an int\n",
    "    if ord(register[0]) >= 97 and ord(register[0]) <= 122:\n",
    "        reg_value=reg[register]\n",
    "    else:\n",
    "        reg_value = register\n",
    "        \n",
    "    #perform commands\n",
    "    if instruct == 'set':\n",
    "        reg[register] = int(value)\n",
    "        \n",
    "    elif instruct =='mul':\n",
    "        reg[register] *= int(value)\n",
    "        mul_count+=1\n",
    "        \n",
    "    elif instruct == 'sub':\n",
    "        reg[register] -= int(value)\n",
    "\n",
    "    elif instruct == 'jnz' and int(reg_value) != 0:\n",
    "        cmd_ptr += int(value)\n",
    "        continue\n",
    "        \n",
    "        \n",
    "    cmd_ptr +=1\n",
    "    \n",
    "print(mul_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2:\n",
    "This one was tricky!  This video was very [helpful](https://www.youtube.com/watch?v=AqXTZo6o34s).\n",
    "\n",
    "Essentially this is a giant loop that is incrementing between 108,100 and 125,100 by 17 and counting the number of non-prime numbers seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "909\n"
     ]
    }
   ],
   "source": [
    "h = 0\n",
    "for i in range(108100,125101,17):\n",
    "    for x in range(2,i):\n",
    "        if i % x == 0:\n",
    "            h+=1\n",
    "            break\n",
    "            \n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 24: Electromagnetic Moat\n",
    "\n",
    "###Part 1:\n",
    "You can treat the bridge components are edges in a undirected graph.  We can than use DFS to find all the potential paths in the graph and determine the one with the greatest sum.  I use dfs_path with a stack to perform dfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1868"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "input = load_data('day24')\n",
    "comps = {}\n",
    "\n",
    "for line in input:\n",
    "    l,r = line.rstrip() .split(\"/\")\n",
    "    comps.setdefault(int(l),set()).add(int(r))\n",
    "    comps.setdefault(int(r),set()).add(int(l))\n",
    "\n",
    "\n",
    "#remove self referencing edges\n",
    "#for num in comps.keys():\n",
    "#    if num in comps[num]:\n",
    "#        comps[num].remove(num)\n",
    "    \n",
    "def dfs_path(graph,start):\n",
    "    paths = []\n",
    "    stack = []\n",
    "    stack.append([start,[start]])\n",
    "    while stack:\n",
    "        node, visited = stack.pop()\n",
    "        for edge_end in graph[node[1]]:\n",
    "            edge = [node[1],edge_end]\n",
    "            if edge not in visited and edge[::-1] not in visited:\n",
    "                paths.append(visited + [edge])\n",
    "                stack.append([edge,visited + [edge]])\n",
    "    return paths\n",
    "\n",
    "max_path =0\n",
    "#paths = dfs_path(comps,[0,2]) + dfs_path(comps,[0,1])\n",
    "paths = dfs_path(comps,[0,9]) + dfs_path(comps,[0,7])\n",
    "for path in paths: \n",
    "    if sum(list(map(sum,path))) > max_path:\n",
    "        max_path =sum(list(map(sum,path)))\n",
    "        \n",
    "max_path\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2:\n",
    "Take the results from part 1 with gives us all the potential paths, to find the longest path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1841\n40\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "max_path = 0\n",
    "for path in paths:\n",
    "        if len(path) >= max_length:\n",
    "            max_path = sum(list(map(sum,path)))\n",
    "            max_length = len(path)\n",
    "            \n",
    "print(max_path)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Day 25: Turing Machine\n",
    "\n",
    "###Part 1:\n",
    "We are using commands in English to modify values in a list.  This is mainly about processing text to determine how to perform the commands.  I just hardcoded the location of important numbers/letters in text for the commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4387\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "input = load_data('day25')\n",
    "turing = []\n",
    "tape = [0] * 1000000\n",
    "ptr = len(tape)//2\n",
    "\n",
    "for line in input:\n",
    "    turing.append(line.rstrip('\\n').lower())\n",
    "\n",
    "#get start state and number of steps    \n",
    "current_state = turing[0][-2]\n",
    "total_steps = int(turing[1].split(\" \")[5])\n",
    "turing = turing[2:]\n",
    "\n",
    "states ={}\n",
    "\n",
    "def get_dir(input):\n",
    "    if input.split(\" \")[-1] == 'right.':\n",
    "        return 1\n",
    "    else:    \n",
    "        return -1\n",
    "    \n",
    "    \n",
    "for i in range(0,len(turing),10):\n",
    "    state = turing[i+1][-2]\n",
    "    #format: what to write, direction to move,next state.  For 0 (first array) and for 1 (second array)\n",
    "    states[state] = [[int(turing[i+3][-2]), get_dir(turing[i+4]),turing[i+5][-2]],\n",
    "                     [int(turing[i+7][-2]), get_dir(turing[i+8]),turing[i+9][-2]]]\n",
    "    \n",
    "for step in range(0,total_steps):\n",
    "    cur_value = tape[ptr]\n",
    "    tape[ptr] = states[current_state][cur_value][0]\n",
    "    ptr += states[current_state][cur_value][1]\n",
    "    current_state = states[current_state][cur_value][2]\n",
    "    \n",
    "print(sum(tape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
